{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KazQ8FKXePOG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aY9K4_WAiZBz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/preprocessed_customers.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05-Un_59jaRb"
      },
      "outputs": [],
      "source": [
        "# Split features and target\n",
        "X = df.drop(columns=['churn'])\n",
        "y = df['churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmvOzPWaidvm"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        " \n",
        "def evaluate_all_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Trains multiple models and prints metrics for easy comparison.\"\"\"\n",
        "\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "        \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42),\n",
        "        \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
        "    }\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        print(f\"Model: {name}\")\n",
        "        print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "        print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "        print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "        print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "        print(\"ROC-AUC  :\", roc_auc_score(y_test, y_proba))\n",
        "        print(\"-\" * 40)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poH-jG_4igdq",
        "outputId": "10ce2b91-5e9e-45ba-d405-53c162386188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy : 0.7444996451383961\n",
            "Precision: 0.5127737226277372\n",
            "Recall   : 0.7513368983957219\n",
            "F1 Score : 0.6095444685466378\n",
            "ROC-AUC  : 0.8367033506419697\n",
            "----------------------------------------\n",
            "Model: Decision Tree\n",
            "Accuracy : 0.7139815471965933\n",
            "Precision: 0.46194225721784776\n",
            "Recall   : 0.47058823529411764\n",
            "F1 Score : 0.46622516556291393\n",
            "ROC-AUC  : 0.6360045467462347\n",
            "----------------------------------------\n",
            "Model: Random Forest\n",
            "Accuracy : 0.7856635911994322\n",
            "Precision: 0.6224489795918368\n",
            "Recall   : 0.4893048128342246\n",
            "F1 Score : 0.5479041916167665\n",
            "ROC-AUC  : 0.8189568317445556\n",
            "----------------------------------------\n",
            "Model: Gradient Boosting\n",
            "Accuracy : 0.7977288857345636\n",
            "Precision: 0.6606498194945848\n",
            "Recall   : 0.4893048128342246\n",
            "F1 Score : 0.5622119815668203\n",
            "ROC-AUC  : 0.8423751582319358\n",
            "----------------------------------------\n",
            "Model: XGBoost\n",
            "Accuracy : 0.7849538679914834\n",
            "Precision: 0.6141479099678456\n",
            "Recall   : 0.5106951871657754\n",
            "F1 Score : 0.5576642335766423\n",
            "ROC-AUC  : 0.8154628122658814\n",
            "----------------------------------------\n",
            "Model: CatBoost\n",
            "Accuracy : 0.7927608232789212\n",
            "Precision: 0.6348684210526315\n",
            "Recall   : 0.516042780748663\n",
            "F1 Score : 0.5693215339233039\n",
            "ROC-AUC  : 0.8369022707897389\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "evaluate_all_models(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmVUjrtRjG5e"
      },
      "source": [
        "**Best Mode: Log Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCyayOtVig_b",
        "outputId": "cf021878-5479-4f67-97ab-4d5a1ac4d8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Accuracy : 0.7444996451383961\n",
            "Precision: 0.5127272727272727\n",
            "Recall   : 0.7540106951871658\n",
            "F1 Score : 0.6103896103896104\n",
            "ROC-AUC  : 0.83668268361363\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# 1. Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# 2. Initialize GridSearchCV with recall as scoring\n",
        "grid = GridSearchCV(\n",
        "    LogisticRegression(class_weight='balanced', max_iter=3000, random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='recall',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 3. Fit on training data\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# 4. Get the best model\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# 5. Predict on test set using threshold 0.5\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_proba >= 0.5).astype(int)\n",
        "\n",
        "# 6. Evaluate metrics\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "print(\"ROC-AUC  :\", roc_auc_score(y_test, y_proba))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCBCDsu9848Y"
      },
      "source": [
        "***SHAP***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nW9EViSE8-z-"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def train_logistic_model(df, target='churn'):\n",
        "    \"\"\"\n",
        "    Train Logistic Regression on preprocessed DataFrame.\n",
        "    Returns the trained model as artifact.\n",
        "    \"\"\"\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "\n",
        "    # Fine-tuned parameters from GridSearch (see ML1_Model_fine-tuning.ipynb in experiments folder)\n",
        "    model = LogisticRegression(\n",
        "        C=1,\n",
        "        penalty='l1',\n",
        "        solver='liblinear',\n",
        "        class_weight='balanced',\n",
        "        max_iter=3000,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X, y)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ8zvrdkjM5z",
        "outputId": "92243569-d232-40b3-dd93-5abac53fe57e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            feature  mean_abs_shap\n",
            "18                contract_Two_year       0.640788\n",
            "12                  monthly_charges       0.550365\n",
            "13                    total_charges       0.534682\n",
            "16     internet_service_Fiber_optic       0.432098\n",
            "17                contract_One_year       0.301210\n",
            "5                   online_security       0.191127\n",
            "19  payment_method_Electronic_check       0.190778\n",
            "15             internet_service_DSL       0.179373\n",
            "8                      tech_support       0.153054\n",
            "11                paperless_billing       0.144058\n",
            "3                     phone_service       0.106654\n",
            "6                     online_backup       0.092179\n",
            "2                        dependents       0.072730\n",
            "10                 streaming_movies       0.068557\n",
            "9                      streaming_tv       0.060561\n",
            "4                    multiple_lines       0.054665\n",
            "20      payment_method_Mailed_check       0.054376\n",
            "0                    senior_citizen       0.053374\n",
            "1                           partner       0.045739\n",
            "7                 device_protection       0.042986\n",
            "21     payment_method_Bank_transfer       0.010039\n",
            "14                      gender_Male       0.004619\n"
          ]
        }
      ],
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "X = df.drop(columns=\"churn\")\n",
        "\n",
        "model = train_logistic_model(df)\n",
        "\n",
        "explainer = shap.LinearExplainer(model, X)\n",
        "shap_values = explainer.shap_values(X)\n",
        "\n",
        "importance = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"mean_abs_shap\": np.abs(shap_values).mean(axis=0)\n",
        "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
        "\n",
        "print(importance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPeTRy3F9A6v",
        "outputId": "a8eb35aa-c333-4f1e-927e-fadb761d915f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            feature  correlation\n",
            "14     internet_service_Fiber_optic     0.308020\n",
            "16                contract_Two_year     0.302253\n",
            "17  payment_method_Electronic_check     0.301919\n",
            "21                    total_charges     0.199037\n",
            "20                  monthly_charges     0.193356\n",
            "11                paperless_billing     0.191825\n",
            "15                contract_One_year     0.177820\n",
            "5                   online_security     0.171226\n",
            "8                      tech_support     0.164674\n",
            "2                        dependents     0.164221\n",
            "0                    senior_citizen     0.150889\n",
            "1                           partner     0.150448\n",
            "13             internet_service_DSL     0.124214\n",
            "19     payment_method_Bank_transfer     0.117937\n",
            "18      payment_method_Mailed_check     0.091683\n",
            "6                     online_backup     0.082255\n",
            "7                 device_protection     0.066160\n",
            "9                      streaming_tv     0.063228\n",
            "10                 streaming_movies     0.061382\n",
            "4                    multiple_lines     0.040102\n",
            "3                     phone_service     0.011942\n",
            "12                      gender_Male     0.008612\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency, pointbiserialr\n",
        "\n",
        "target = \"churn\"\n",
        "\n",
        "# Binary features (exclude numeric ones explicitly)\n",
        "binary_cols = [\n",
        "    c for c in df.columns\n",
        "    if c not in [target, \"monthly_charges\", \"total_charges\"]\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "# Phi correlation: binary ↔ binary\n",
        "for col in binary_cols:\n",
        "    table = pd.crosstab(df[col], df[target])\n",
        "    chi2 = chi2_contingency(table, correction=False)[0]\n",
        "    n = table.sum().sum()\n",
        "    phi = (chi2 / n) ** 0.5\n",
        "    results.append((col, phi))\n",
        "\n",
        "# Point-biserial: numeric ↔ binary\n",
        "for col in [\"monthly_charges\", \"total_charges\"]:\n",
        "    r, _ = pointbiserialr(df[target], df[col])\n",
        "    results.append((col, abs(r)))\n",
        "\n",
        "corr_df = pd.DataFrame(results, columns=[\"feature\", \"correlation\"]) \\\n",
        "            .sort_values(\"correlation\", ascending=False)\n",
        "\n",
        "print(corr_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrTrIC-bAnMN"
      },
      "source": [
        "**Check performance after dropping some columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWkA4ZCb_qDq",
        "outputId": "77ba7121-0a37-4716-dd1b-7d0544699f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   accuracy    recall  precision  f1_score   roc_auc\n",
            "0  0.740951  0.764706   0.507993  0.610459  0.833459\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
        "\n",
        "# 1. Drop weak features\n",
        "drop_cols = [\"gender_Male\", \"phone_service\", \"multiple_lines\", 'streaming_tv','streaming_movies','online_backup','device_protection']\n",
        "df_reduced = df.drop(columns=drop_cols)\n",
        "\n",
        "# 2. Split\n",
        "X = df_reduced.drop(columns=\"churn\")\n",
        "y = df_reduced[\"churn\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 3. Train model\n",
        "model = train_logistic_model(pd.concat([X_train, y_train], axis=1))\n",
        "\n",
        "# 4. Predict\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 5. Metrics\n",
        "metrics = {\n",
        "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"recall\": recall_score(y_test, y_pred),\n",
        "    \"precision\": precision_score(y_test, y_pred),\n",
        "    \"f1_score\": f1_score(y_test, y_pred),\n",
        "    \"roc_auc\": roc_auc_score(y_test, y_proba)\n",
        "}\n",
        "\n",
        "print(pd.DataFrame(metrics, index=[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnoDnNDcB4vv"
      },
      "source": [
        "# Feature Reduction Analysis\n",
        "\n",
        "## 1. Comparison with Original Model\n",
        "\n",
        "| Metric    | Original | After Dropping 7 Features | Δ (Change) |\n",
        "|----------|---------|---------------------------|------------|\n",
        "| Accuracy | 0.7445  | 0.7410                    | -0.0035    |\n",
        "| Recall   | 0.7513  | 0.7647                    | +0.0134    |\n",
        "| Precision| 0.5128  | 0.5080                    | -0.0048    |\n",
        "| F1 Score | 0.6095  | 0.6105                    | +0.0010    |\n",
        "| ROC-AUC  | 0.8367  | 0.8335                    | -0.0032    |\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Interpretation\n",
        "\n",
        "- **Recall increased slightly:** The model catches slightly more churners — often good in business applications.  \n",
        "- **F1 Score roughly unchanged:** Slight increase — the model balances precision and recall well.  \n",
        "- **Accuracy & ROC-AUC slightly decreased:** Tiny drop (<0.5%), negligible in practice.  \n",
        "- **Precision decreased slightly:** Small trade-off for higher recall — typical when removing weak/noisy features.\n",
        "\n",
        "**Conclusion:**  \n",
        "Even after removing 7 features, performance remains essentially stable. The model is simpler, more interpretable, and almost identical in predictive power.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Takeaways\n",
        "\n",
        "1. **Safe reduction:** Successfully reduced 7+ features with minimal performance loss.  \n",
        "2. **Further reduction possible:** Consider aggregating or dropping very low-correlation features if needed.  \n",
        "3. **Better interpretability:** SHAP values and model coefficients now focus on the truly important features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hecpQqxoAs-p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
